{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datos = pd.read_csv('data.csv')\n",
    "\n",
    "X=datos.drop(['PRED'], axis=1)\n",
    "y = datos['PRED']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "model1 = RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=15,\n",
    "                       max_leaf_nodes=50, min_samples_leaf=4,\n",
    "                       min_samples_split=10, n_estimators=800, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "              \n",
    "model2 = MLPClassifier(alpha=0.012273800987852959, beta_1=0.2788441133807552,\n",
    "              beta_2=0.10551659500647881, epsilon=8.254614284548341e-08,\n",
    "              hidden_layer_sizes=(850,), learning_rate='adaptive',\n",
    "              learning_rate_init=0.014477786306928656,\n",
    "              momentum=0.6453639773029103, random_state=42, solver='sgd').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model = ensemble_clf = VotingClassifier(estimators=[('rf', model1), ('ann', model2)], voting='soft').fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "#Cross-validationz\n",
    "def confusion_matrix_scorer(model, X_train, y_train):\n",
    "        y_pred = model.predict(X_train)\n",
    "        cm = confusion_matrix(y_train, y_pred)\n",
    "        return {'tn': cm[0, 0], 'fp': cm[0, 1],\n",
    "                'fn': cm[1, 0], 'tp': cm[1, 1]}\n",
    "        \n",
    "cv_results = cross_validate(model, X_train, y_train, cv=10,\n",
    "                            scoring=confusion_matrix_scorer)\n",
    "# Getting the test set true positive scores\n",
    "TP = cv_results['test_tp'].mean()\n",
    "\n",
    "# Getting the test set false negative scores\n",
    "FN = cv_results['test_fn'].mean()\n",
    "\n",
    "# Getting the test set false positive scores\n",
    "FP = cv_results['test_fp'].mean()\n",
    "\n",
    "# Getting the test set true negative scores\n",
    "TN = cv_results['test_tn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Perform cross-validation and obtain predictions\n",
    "y_scores = cross_val_predict(model, X_train, y_train, cv=10, method='predict_proba')\n",
    "\n",
    "# Compute ROC curve for each cross-validation fold\n",
    "fprs, tprs, aucs = [], [], []\n",
    "for i in range(10):\n",
    "    fpr, tpr, _ = roc_curve(y_train, y_scores[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "# Compute average ROC curve\n",
    "mean_fpr = np.mean(fprs, axis=0)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = np.mean(aucs)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_fpr, mean_tpr, color='darkblue', label=f'Mean ROC (AUC = {mean_auc:.2f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', color=\"red\")\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC curve on training dataset')\n",
    "ax.legend()\n",
    "plt.savefig('hy_paac_training_remove.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate and true positive rate\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate area under the curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='darkgreen', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve on testing dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('hy_paac_testing_remove.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TRAINING###\n",
    "import numpy as np\n",
    "\n",
    "acurracy = (TP+TN) / (TP+TN+FP+FN)\n",
    "F1_score = 2*TP / ((2*TP) + (FP + FN))\n",
    "precision = TP / (TP + FP)\n",
    "specificity = TN / (FP + TN)\n",
    "sensitivity_recall = TP / (TP + FN)\n",
    "\n",
    "def cohen_kappa(TP, FP, TN, FN):\n",
    "    N = TP + FP + TN + FN\n",
    "    Po = (TP + TN) / N\n",
    "    Pe = ((TP + FP) * (TP + FN) + (TN + FP) * (TN + FN)) / N**2\n",
    "    return (Po - Pe) / (1 - Pe)\n",
    "\n",
    "kappa = cohen_kappa(TP=TP, FP=FP, TN=TN, FN=FN)\n",
    "\n",
    "import math \n",
    "MCC = ((TP*TN) - (FP*FN)) / math.sqrt(((TP+FP)*(TP+FN))*((TN+FP)*(TN+FN)))\n",
    "\n",
    "print(\"Accuracy: \", acurracy)\n",
    "print(\"F1_score: \", F1_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Specificity: \", specificity)\n",
    "print(\"Sensitivity/Recall: \", sensitivity_recall)\n",
    "print(\"Kappa: \", kappa)\n",
    "print(\"MCC: \", MCC)\n",
    "print(\"Mean_AUC: \", mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TESTING###\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_test=model.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(y_test, pred_test)\n",
    "TPt = conf[1, 1]\n",
    "FPt = conf[0, 1]\n",
    "TNt = conf[0, 0]\n",
    "FNt = conf[1, 0]\n",
    "\n",
    "acurracy = (TPt+TNt) / (TPt+TNt+FPt+FNt)\n",
    "F1_score = 2*TPt / ((2*TPt) + (FPt + FNt))\n",
    "precision = TPt / (TPt + FPt)\n",
    "specificity = TNt / (FPt + TNt)\n",
    "sensitivity_recall = TPt / (TPt + FNt)\n",
    "\n",
    "def cohen_kappa(TPt, FPt, TNt, FNt):\n",
    "    N = TPt + FPt + TNt + FNt\n",
    "    Po = (TPt + TNt) / N\n",
    "    Pe = ((TPt + FPt) * (TPt + FNt) + (TNt + FPt) * (TNt + FNt)) / N**2\n",
    "    return (Po - Pe) / (1 - Pe)\n",
    "\n",
    "kappa = cohen_kappa(TPt, FPt, TNt, FNt)\n",
    "\n",
    "import math \n",
    "MCC = ((TPt*TNt) - (FPt*FNt)) / math.sqrt(((TPt+FPt)*(TPt+FNt))*((TNt+FPt)*(TNt+FNt)))\n",
    "\n",
    "print(\"Accuracy: \", acurracy)\n",
    "print(\"F1_score: \", F1_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Specificity: \", specificity)\n",
    "print(\"Sensitivity/Recall: \", sensitivity_recall)\n",
    "print(\"Kappa: \", kappa)\n",
    "print(\"MCC: \", MCC)\n",
    "print(\"AUC: \", roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
